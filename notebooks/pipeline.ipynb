{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "import pandas as pd\n",
    "\n",
    "from src.pipeline import Pipeline\n",
    "from src.preprocessing.preprocessing import tokenization, removal, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "collection = pd.read_csv('../data/TREC_Passage/collection.tsv', sep='\\t', names=[\"pID\", \"Passage\"], header=None)\n",
    "queries = pd.read_csv('../data/TREC_Passage/queries.dev.tsv', sep='\\t', names=[\"qID\", \"Query\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(collection = '../data/raw/collection.pkl', queries = '../data/raw/queries.pkl')\n",
    "#pipeline = Pipeline(collection = collection, queries = queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          The presence of communication amid scientific ...\n",
       "1          The Manhattan Project and its atomic bomb help...\n",
       "2          Essay on The Manhattan Project - The Manhattan...\n",
       "3          The Manhattan Project was the name for a proje...\n",
       "4          versions of each volume as well as complementa...\n",
       "                                 ...                        \n",
       "8841818    When metal salts emit short wavelengths of vis...\n",
       "8841819    Thousands of people across the United States w...\n",
       "8841820    The recipe that creates blue, for example, inc...\n",
       "8841821    On Independence Days of yore, old-timey crowds...\n",
       "8841822    View full size image. Behind the scenes of the...\n",
       "Name: Passage, Length: 8841823, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.Passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1048578</td>\n",
       "      <td>cost of endless pools/swim spa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1048579</td>\n",
       "      <td>what is pcnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1048580</td>\n",
       "      <td>what is pcb waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1048581</td>\n",
       "      <td>what is pbis?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048582</td>\n",
       "      <td>what is paysky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qID                           Query\n",
       "0  1048578  cost of endless pools/swim spa\n",
       "1  1048579                    what is pcnt\n",
       "2  1048580               what is pcb waste\n",
       "3  1048581                   what is pbis?\n",
       "4  1048582                  what is paysky"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = collection.Passage[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 243.15it/s]\n"
     ]
    }
   ],
   "source": [
    "x = x.progress_apply(lambda text: np.array(\n",
    "            stemming(\n",
    "                removal(\n",
    "                    tokenization(text)\n",
    "                ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "embedding = ELMoEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# embed words in sentence\n",
    "# create a sentence\n",
    "import torch\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)\n",
    "\n",
    "input = torch.empty(sentence[0].embedding.size())\n",
    "tokens_per_sentence = torch.zeros_like(input)\n",
    "\n",
    "for token in sentence:\n",
    "    tokens_per_sentence = torch.add(tokens_per_sentence, token.embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "from flair.data import Sentence\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "\n",
    "class Elmo(object):\n",
    "    def __init__(self):\n",
    "        # init embedding\n",
    "        self.embedding = ELMoEmbeddings()\n",
    "\n",
    "    def transform(self, X):\n",
    "        elmo_list = []\n",
    "        for line in tqdm(X):\n",
    "            detokenized = TreebankWordDetokenizer().detokenize(line)\n",
    "            sentence = Sentence(detokenized)\n",
    "            #self.embedding.embed(sentence)\n",
    "            #sentence = Sentence(line)\n",
    "            input = torch.empty(sentence[0].embedding.size())\n",
    "            tokens_per_sentence = torch.zeros_like(input)\n",
    "            self.embedding.embed(sentence)\n",
    "            for token in sentence:\n",
    "                tokens_per_sentence = torch.add(tokens_per_sentence, token.embedding)\n",
    "            elmo_list.append(tokens_per_sentence)\n",
    "        return np.array(elmo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "from flair.data import Sentence\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "class Elmo(object):\n",
    "    def __init__(self):\n",
    "        # init embedding\n",
    "        self.embedding = ELMoEmbeddings()\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        elmo_list = []\n",
    "        for line in tqdm(X):\n",
    "            detokenized = TreebankWordDetokenizer().detokenize(line)\n",
    "            sentence = Sentence(detokenized)\n",
    "            self.embedding.embed(sentence)\n",
    "            input = torch.empty(sentence[0].embedding.size())\n",
    "            tokens_per_sentence = torch.zeros_like(input)\n",
    "            for token in sentence:\n",
    "                tokens_per_sentence = torch.add(tokens_per_sentence, token.embedding)\n",
    "            elmo_list.append(tokens_per_sentence)\n",
    "        return np.array(elmo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:17<00:00,  2.23it/s]\n",
      "c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages\\ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "el = Elmo()\n",
    "output = el.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([tensor([-4.9217, -1.4432,  4.2792,  ...,  5.8397, 36.4698,  4.1877]),\n",
       "       tensor([-3.7379e+00, -2.2561e+00,  1.5099e-02,  ...,  1.5140e+00,\n",
       "                3.6263e+01, -2.1968e+00])                               ,\n",
       "       tensor([-0.4364, -1.7102, -3.0806,  ...,  4.9637, 25.7533,  4.8212]),\n",
       "       tensor([-1.5862, -2.1382, -4.6523,  ...,  4.6862, 35.8381,  4.3871]),\n",
       "       tensor([ -4.6053,  -4.5531,  -0.9315,  ..., -17.8543,  50.0152,  -4.6643]),\n",
       "       tensor([-2.9713, -1.6235,  1.1651,  ..., 14.4024, 50.3542,  4.7282]),\n",
       "       tensor([ 1.2184, -2.4923, -0.3482,  ..., 10.2864, 23.6172, -5.8068]),\n",
       "       tensor([ -0.8632,  -2.2151,  -2.3177,  ...,  -7.8934,  85.5076, -15.9382]),\n",
       "       tensor([-1.6970,  1.1990, -0.8303,  ...,  2.7465, 10.9501,  1.6276]),\n",
       "       tensor([-2.9909e-02,  1.2811e+00,  1.9970e-01,  ..., -1.0623e+01,\n",
       "                4.7564e+01,  3.6053e+00])                               ,\n",
       "       tensor([-0.0537, -3.2913,  3.3061,  ..., -8.0761, 42.2549,  2.1429]),\n",
       "       tensor([-0.1102, -0.1927,  3.6771,  ...,  1.9139,  3.6327,  0.5152]),\n",
       "       tensor([ -3.4124,   1.8577,   4.7019,  ..., -25.2042,  65.9429, -12.1319]),\n",
       "       tensor([-3.3938, -0.7395,  4.9844,  ...,  2.7769, 13.4991, -2.5522]),\n",
       "       tensor([ -4.4431,   4.5619,   0.1987,  ..., -10.0880,  31.3451,  -9.2075]),\n",
       "       tensor([-0.9654, -6.2613,  6.4314,  ..., -3.9985, 50.4494, -5.0099]),\n",
       "       tensor([-0.7397,  0.1483,  2.5532,  ...,  1.8983, 11.7724,  6.4226]),\n",
       "       tensor([ -0.7793,   1.0370,  -5.6270,  ..., -12.3022,  49.4320,  -6.0884]),\n",
       "       tensor([  0.5684,   0.4805,  -5.3460,  ..., -11.4992,  34.2592,  -3.6593]),\n",
       "       tensor([  0.9439,  -2.3258,   6.5161,  ..., -11.4096,  33.4151,  -2.4776]),\n",
       "       tensor([ 3.0918, -0.3791,  5.0892,  ...,  0.4417, 37.9161,  2.2721]),\n",
       "       tensor([-0.3711, -3.1366,  7.3756,  ..., 11.8122, 11.6270,  0.2590]),\n",
       "       tensor([ 0.3762, -0.7300,  6.4652,  ...,  3.5822, 12.7121, -0.1916]),\n",
       "       tensor([ 0.6148,  2.0001,  4.3925,  ...,  5.6079, 18.7344,  6.9863]),\n",
       "       tensor([-5.2379, -2.2386,  4.6984,  ...,  2.8464, 22.9284,  9.6321]),\n",
       "       tensor([-8.8130,  0.2272,  7.1011,  ...,  1.9844, 36.8579, 29.6234]),\n",
       "       tensor([-2.5271, -3.4353,  0.6534,  ..., -5.4381, 23.9419,  0.7379]),\n",
       "       tensor([ 2.6922, -1.8634,  2.9186,  ..., -1.1308, 26.1224,  1.8588]),\n",
       "       tensor([-3.2766,  0.4515,  6.7273,  ...,  7.5841, 23.5459, 12.9500]),\n",
       "       tensor([-2.7324,  1.0390,  3.4272,  ..., -4.8241, 20.7336,  0.9445]),\n",
       "       tensor([ 7.0935e-03, -7.1571e-01,  3.0651e+00,  ..., -1.6270e+00,\n",
       "                2.8200e+01,  1.6441e+01])                               ,\n",
       "       tensor([ 3.1036, -2.7357,  0.8016,  ..., -4.4056, 37.0977, -6.0586]),\n",
       "       tensor([-1.2748e+00,  2.3233e-02,  5.1316e+00,  ...,  5.0373e+00,\n",
       "                4.0830e+01, -7.6145e+00])                               ,\n",
       "       tensor([-3.6755, -0.4970,  4.1303,  ...,  4.1210, 32.6731, -4.6506]),\n",
       "       tensor([-2.3669,  3.1864,  0.1313,  ...,  6.3056, 38.3387,  6.2669]),\n",
       "       tensor([-0.2315, -0.7146,  1.2142,  ..., -4.6067, 23.5755,  4.4022]),\n",
       "       tensor([-1.2366,  1.0338, -1.2432,  ..., 14.0354, 32.4144,  0.3062]),\n",
       "       tensor([-1.4385,  2.4219, -0.7051,  ...,  3.9638, 44.2172,  7.8018]),\n",
       "       tensor([ 0.2259, -0.6653,  3.3429,  ..., -0.2621, 28.4516,  0.0541]),\n",
       "       tensor([ 0.2058, -2.9232,  6.4071,  ..., -5.0922, 41.8354,  4.0174])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.8.0\n",
      "Uninstalling tensorflow-2.8.0:\n",
      "  Successfully uninstalled tensorflow-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\", line 89, in run\n",
      "    uninstall_pathset.commit()\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 442, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 282, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 339, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 430, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 378, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 206, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 433, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 507, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 386, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 386, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 386, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  [Previous line repeated 1 more times]\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 391, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\D073999\\AppData\\Local\\Programs\\Python\\Python37\\lib\\shutil.py\", line 389, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'c:\\\\users\\\\d073999\\\\documents\\\\priv-dev\\\\retriever\\\\lib\\\\site-packages\\\\~ensorflow\\\\lite\\\\experimental\\\\microfrontend\\\\python\\\\ops\\\\_audio_microfrontend_op.so'\n",
      "WARNING: Skipping tensorflow-cloud as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting tensorflow==1.15\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/94/a9/7a9ff9b51a6acf5cf113e79e4cfd68a88045321cfc65802c16169dfcd041/tensorflow-1.15.0-cp37-cp37m-win_amd64.whl (295.1 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (0.36.2)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (3.3.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.44.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.14.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (3.20.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.16.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorflow==1.15) (1.21.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.6.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.8.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\d073999\\documents\\priv-dev\\retriever\\lib\\site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=2e79851a5a64d77ddea493df99b35153515a67e6f636e2315774d102362af3c8\n",
      "  Stored in directory: c:\\users\\d073999\\appdata\\local\\pip\\cache\\wheels\\72\\f2\\b3\\e50dc833b3e9829b60168ad4921ee7ccbfffe6738204b06a38\n",
      "Successfully built gast\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, astor, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\D073999\\Documents\\Priv-Dev\\Retriever\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!pip uninstall tensorflow-cloud -y\n",
    "!pip install -U tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pytorch-lightning as it is not installed.\n",
      "WARNING: Skipping tensorflow-probability as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pytorch-lightning -y\n",
    "!pip uninstall tensorflow-probability -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tensorflow Hub ELMO-2\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/2\").signatures[\"default\"]\n",
    "\n",
    "def create_elmo_embeddings(data):\n",
    "    embed=elmo(\n",
    "        tf.constant(data))[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        sess.run(tf.compat.v1.tables_initializer())\n",
    "        out_x=sess.run(embed)\n",
    "        #out_y=ses.run(tf.reduce_mean(embed,1))\n",
    "        return out_x\n",
    "z=queries.Query.tolist()\n",
    "elmo_input=z[:2]\n",
    "elmo_output=create_elmo_embeddings(elmo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = collection.Passage[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     The presence of communication amid scientific ...\n",
       "1     The Manhattan Project and its atomic bomb help...\n",
       "2     Essay on The Manhattan Project - The Manhattan...\n",
       "3     The Manhattan Project was the name for a proje...\n",
       "4     versions of each volume as well as complementa...\n",
       "5     The Manhattan Project. This once classified ph...\n",
       "6     Nor will it attempt to substitute for the extr...\n",
       "7     Manhattan Project. The Manhattan Project was a...\n",
       "8     In June 1942, the United States Army Corps of ...\n",
       "9     One of the main reasons Hanford was selected a...\n",
       "10    group discussions, community boards or panels ...\n",
       "11    punishment designed to repair the damage done ...\n",
       "12    Tutorial: Introduction to Restorative Justice....\n",
       "13    Organize volunteer community panels, boards, o...\n",
       "14    The purpose of this paper is to point out a nu...\n",
       "15    Each of these types of communitiesâthe geogr...\n",
       "16    The approach is based on a theory of justice t...\n",
       "17    Inherent in many peopleâs understanding of t...\n",
       "18    Criminal justice, however, is not usually conc...\n",
       "19    The circle includes a wide range of participan...\n",
       "20    Phloem is a conductive (or vascular) tissue fo...\n",
       "21    Phloem and xylem are complex tissues that perf...\n",
       "22    Phloem and xylem are complex tissues that perf...\n",
       "23    Phloem is a conductive (or vascular) tissue fo...\n",
       "24    Unlike xylem (which is composed primarily of d...\n",
       "25    In xylem vessels water travels by bulk flow ra...\n",
       "26    The mechanism by which sugars are transported ...\n",
       "27    Phloem carries the products of photosynthesis ...\n",
       "28    Xylem transports water and soluble mineral nut...\n",
       "29    At this time the Industrial Workers of the Wor...\n",
       "30    This was not true of the Industrial Workers of...\n",
       "31    Chinese Immigration and the Chinese Exclusion ...\n",
       "32    The Rise of Industrial America, 1877-1900. Whe...\n",
       "33    American objections to Chinese immigration too...\n",
       "34    The rise of industrial America, the dominance ...\n",
       "35    The resulting Angell Treaty permitted the Unit...\n",
       "36    Industrial Workers of the World. In 1905 repre...\n",
       "37    The railroads powered the industrial economy. ...\n",
       "38    This finally resulted in legislation that aime...\n",
       "39    Costa Rica is known as a prime Eco-tourism des...\n",
       "Name: Passage, dtype: object"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x.tolist()\n",
    "elmo_input=z[:2]\n",
    "elmo_output=create_elmo_embeddings(elmo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "  embeddings = []\n",
    "  for elm in x:\n",
    "        print(elm)\n",
    "        e = elmo(elm.tolist())[\"elmo\"]\n",
    "        embeddings.append(elmo(x.tolist())[\"elmo\"])\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    # return average of ELMo features\n",
    "    return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 367.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     [presenc, commun, amid, scientif, mind, equal,...\n",
       "1     [manhattan, project, atom, bomb, help, bring, ...\n",
       "2     [essay, manhattan, project, manhattan, project...\n",
       "3     [manhattan, project, name, project, conduct, w...\n",
       "4     [version, volum, well, complementari, websit, ...\n",
       "5     [manhattan, project, classifi, photograph, fea...\n",
       "6     [attempt, substitut, extraordinarili, rich, li...\n",
       "7     [manhattan, project, manhattan, project, resea...\n",
       "8     [june, 1942, unit, state, armi, corp, engineer...\n",
       "9     [one, main, reason, hanford, select, site, man...\n",
       "10    [group, discuss, commun, board, panel, third, ...\n",
       "11    [punish, design, repair, damag, done, victim, ...\n",
       "12    [tutori, introduct, restor, justic, restor, ju...\n",
       "13    [organ, volunt, commun, panel, board, committe...\n",
       "14    [purpos, paper, point, number, unresolv, issu,...\n",
       "15    [type, communitiesâth, geograph, commun, vic...\n",
       "16    [approach, base, theori, justic, consid, crime...\n",
       "17    [inher, mani, peopleâ, understand, notion, a...\n",
       "18    [crimin, justic, howev, usual, conceptualis, d...\n",
       "19    [circl, includ, wide, rang, particip, includ, ...\n",
       "20    [phloem, conduct, vascular, tissu, found, plan...\n",
       "21    [phloem, xylem, complex, tissu, perform, trans...\n",
       "22    [phloem, xylem, complex, tissu, perform, trans...\n",
       "23    [phloem, conduct, vascular, tissu, found, plan...\n",
       "24    [unlik, xylem, compos, primarili, dead, cell, ...\n",
       "25    [xylem, vessel, water, travel, bulk, flow, rat...\n",
       "26    [mechan, sugar, transport, phloem, sourc, sink...\n",
       "27    [phloem, carri, product, photosynthesi, sucros...\n",
       "28    [xylem, transport, water, solubl, miner, nutri...\n",
       "29    [time, industri, worker, world, membership, 10...\n",
       "30    [true, industri, worker, world, result, mani, ...\n",
       "31    [chines, immigr, chines, exclus, act, 1850, ch...\n",
       "32    [rise, industri, america, 18771900, 1873, mark...\n",
       "33    [american, object, chines, immigr, took, mani,...\n",
       "34    [rise, industri, america, domin, wage, labor, ...\n",
       "35    [result, angel, treati, permit, unit, state, r...\n",
       "36    [industri, worker, world, 1905, repres, 43, gr...\n",
       "37    [railroad, power, industri, economi, consum, m...\n",
       "38    [final, result, legisl, aim, limit, futur, imm...\n",
       "39    [costa, rica, known, prime, ecotour, destin, v...\n",
       "Name: Passage, dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.progress_apply(lambda text: np.array(\n",
    "            stemming(\n",
    "                removal(\n",
    "                    tokenization(text)\n",
    "                ))));x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presenc commun amid scientif mind equal import success manhattan project scientif intellect cloud hang impress achiev atom research engin success truli meant hundr thousand innoc live obliter',\n",
       " 'manhattan project atom bomb help bring end world war ii legaci peac use atom energi continu impact histori scienc',\n",
       " 'essay manhattan project manhattan project manhattan project see make atom bomb possibl success project would forev chang world forev make known someth power manmad',\n",
       " 'manhattan project name project conduct world war ii develop first atom bomb refer specif period project 194 â\\x80¦ 21946 control us armi corp engin administr gener lesli r grove',\n",
       " 'version volum well complementari websit first websiteâ\\x80\\x93th manhattan project interact historyâ\\x80\\x93i avail offic histori heritag resourc websit http wwwcfo doegovme70histori offic histori heritag resourc nation nuclear secur',\n",
       " 'manhattan project classifi photograph featur first atom bomb â\\x80\\x94 weapon atom scientist nicknam gadget nuclear age began juli 16 1945 deton new mexico desert',\n",
       " 'attempt substitut extraordinarili rich literatur atom bomb end world war ii collect attempt document origin develop manhattan project',\n",
       " 'manhattan project manhattan project research develop undertak world war ii produc first nuclear weapon led unit state support unit kingdom canada 1942 1946 project direct major gener lesli grove us armi corp engin nuclear physicist robert oppenheim director lo alamo laboratori design actual bomb armi compon project design',\n",
       " 'june 1942 unit state armi corp engineersbegan manhattan project secret name 2 atom bomb',\n",
       " 'one main reason hanford select site manhattan project b reactor proxim columbia river largest river flow pacif ocean north american coast',\n",
       " 'group discuss commun board panel third parti victim offend dialogu requir skill facilit also suffici understand sexual assault domest violenc date violenc well trauma safeti issu',\n",
       " 'punish design repair damag done victim commun offend crimin act ex commun servic big brother program indetermin sentenc',\n",
       " 'tutori introduct restor justic restor justic theori justic emphas repair harm caus crimin behaviour best accomplish cooper process includ stakehold lead transform peopl relationship commun practic program reflect restor purpos respond crime 1 identifi take step repair harm 2 involv stakehold 3 transform tradit relationship commun govern respond crime',\n",
       " 'organ volunt commun panel board committe meet offend discuss incid offend oblig repair harm victim commun member facilit process apolog victim commun invit local victim advoc provid ongo victimawar train probat staff',\n",
       " 'purpos paper point number unresolv issu crimin justic system present underli principl restor justic review grow amount empir data victimoffend mediat',\n",
       " 'type communitiesâ\\x80\\x94th geograph commun victim offend crime commun care civil societyâ\\x80\\x94may injur crime differ way degre affect common way well sens safeti confid member threaten order within commun threaten depend kind crime common valu commun challeng perhap erod',\n",
       " 'approach base theori justic consid crime wrongdo offens individu commun rather state restor justic foster dialogu victim offend shown highest rate victim satisfact offend account',\n",
       " 'inher mani peopleâ\\x80\\x99 understand notion adr exist disput identifi parti crimin justic howev usual conceptualis disput victim offend instead seen matter concern relationship offend state rais complex question whether crimin offenc properli describ â\\x80\\x98disputeâ\\x80\\x99',\n",
       " 'crimin justic howev usual conceptualis disput victim offend instead seen matter concern relationship offend state 3 rais complex question whether crimin offenc properli describ â\\x80\\x98disputeâ\\x80\\x99',\n",
       " 'circl includ wide rang particip includ offend victim also friend famili commun member justic system repres primari distinct conferenc circl circl focu exclus offens limit solut repair harm victim offend',\n",
       " 'phloem conduct vascular tissu found plant phloem carri product photosynthesi sucros glucos leav part plant â\\x80¦ correspond system circul water miner root call xylem',\n",
       " 'phloem xylem complex tissu perform transport food water plant vascular tissu plant togeth form vascular bundl work togeth unit bring effect transport food nutrient miner water',\n",
       " 'phloem xylem complex tissu perform transport food water plant vascular tissu plant togeth form vascular bundl',\n",
       " 'phloem conduct vascular tissu found plant phloem carri product photosynthesi sucros glucos leav part plant',\n",
       " 'unlik xylem compos primarili dead cell phloem compos stillliv cell transport sap sap waterbas solut rich sugar made photosynthet area',\n",
       " 'xylem vessel water travel bulk flow rather cell diffus phloem concentr organ substanc insid phloem cell eg leaf creat diffus gradient water flow cell phloem sap move sourc organ substanc sugar sink turgor pressur',\n",
       " 'mechan sugar transport phloem sourc sink call pressur flow sourc usual leav sugar molecul move siev element phloem cell activ transport',\n",
       " 'phloem carri product photosynthesi sucros glucos leav part plant â\\x80¦ correspond system circul water miner root call xylem',\n",
       " 'xylem transport water solubl miner nutrient root variou part plant respons replac water lost transpir photosynthesi phloem transloc sugar made photosynthet area plant storag organ like root tuber bulb',\n",
       " 'time industri worker world membership 100000 member 1913 william haywood replac vincent saint john secretarytreasur industri worker world time iww 100000 member',\n",
       " 'true industri worker world result mani member first second gener immigr sever immigr mari mother jone hubert harrison carlo tresca arturo giovannitti joe haaglund hill becam leader organ',\n",
       " 'chines immigr chines exclus act 1850 chines worker migrat unit state first work gold mine also take agricultur job factori work especi garment industri',\n",
       " 'rise industri america 18771900 1873 mark twain charl dudley warner entitl coauthor novel gild age gave late nineteenth centuri popular name term reflect combin outward wealth dazzl inner corrupt poverti',\n",
       " 'american object chines immigr took mani form gener stem econom cultur tension well ethnic discrimin chines labor came unit state order send money back china support famili',\n",
       " 'rise industri america domin wage labor growth citi repres perhap greatest chang period american end civil war anticip rapid rise american industri',\n",
       " 'result angel treati permit unit state restrict complet prohibit chines immigr 1882 congress pass chines exclus act per term angel treati suspend immigr chines labor skill unskil period 10 year',\n",
       " 'industri worker world 1905 repres 43 group oppos polici american feder labour form radic labour organis industri worker world iww iww goal promot worker solidar revolutionari struggl overthrow employ class',\n",
       " 'railroad power industri economi consum major iron steel produc unit state 1890 late 1882 steel rail account 90 percent steel product unit state nationâ\\x80\\x99 largest consum lumber major consum coal',\n",
       " 'final result legisl aim limit futur immigr chines worker unit state threaten sour diplomat relat unit state china',\n",
       " 'costa rica known prime ecotour destin visitor assur majest view amaz destin spot temper climat factor assur medic tourist excel vacat experi conduc recoveri relax']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "output = []\n",
    "for tokens in x:\n",
    "    r =TreebankWordDetokenizer().detokenize(tokens)\n",
    "    output.append(r)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=output#.tolist()\n",
    "elmo_input=z[:2]\n",
    "elmo_output=create_elmo_embeddings(elmo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.16142987,  0.39164305,  0.2924859 , ..., -0.10307619,\n",
       "          0.47838593,  0.10405383],\n",
       "        [ 0.103149  , -0.20897631,  0.40901518, ..., -0.14926252,\n",
       "          0.6624829 , -0.18022116],\n",
       "        [-0.24741618,  0.30307624, -0.5055893 , ..., -0.26527908,\n",
       "          0.17358826, -0.03860291],\n",
       "        ...,\n",
       "        [-0.12553898, -0.13239129, -0.04669396, ..., -0.32613608,\n",
       "          0.5977138 ,  0.13836601],\n",
       "        [ 0.5781988 , -0.35236633, -0.37354636, ..., -0.38017738,\n",
       "          0.07846026,  0.09849334],\n",
       "        [ 0.1008294 , -0.49969184, -0.3491489 , ...,  0.12266825,\n",
       "          0.16703467,  0.42627513]],\n",
       "\n",
       "       [[ 0.306329  ,  0.4091187 ,  0.48765004, ...,  0.13162018,\n",
       "          0.62339723, -0.22805919],\n",
       "        [ 0.7706266 , -0.03343945,  0.12615913, ...,  0.03431229,\n",
       "          0.20650187, -0.33816066],\n",
       "        [-0.01331159,  0.18552707, -0.15152037, ...,  0.21959701,\n",
       "          0.87772703,  0.6102616 ],\n",
       "        ...,\n",
       "        [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
       "         -0.01429836, -0.01650422],\n",
       "        [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
       "         -0.01429836, -0.01650422],\n",
       "        [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
       "         -0.01429836, -0.01650422]]], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elmo_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}